import pandas as pd
import requests
import time
import warnings
import json
import os
from akshare.stock.cons import xq_a_token
import akshare as ak

warnings.filterwarnings("ignore")

# ====================== è‡ªé€‰è‚¡æŒä¹…åŒ–é…ç½® ======================
SELF_SELECTED_FILE = "self_selected_stocks.json"
DEFAULT_STOCKS = [
    {"code": "600000", "name": "æµ¦å‘é“¶è¡Œ"},
    {"code": "000001", "name": "å¹³å®‰é“¶è¡Œ"},
    {"code": "601318", "name": "ä¸­å›½å¹³å®‰"}
]

def load_self_selected_stocks():
    """åŠ è½½è‡ªé€‰è‚¡æ•°æ®ï¼ˆä¿®å¤åŸç”Ÿå­—ç¬¦ä¸²replaceå‚æ•°ï¼‰"""
    try:
        if os.path.exists(SELF_SELECTED_FILE):
            with open(SELF_SELECTED_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            if isinstance(data, list) and len(data) > 0:
                # å¼ºåˆ¶è¡¥å…¨6ä½ä»£ç  + æ¸…æ´—åç§°ç©ºæ ¼ï¼ˆä¿®å¤ï¼šå»æ‰regex=Falseï¼‰
                for item in data:
                    item["code"] = str(item["code"]).strip().zfill(6)
                    if "name" in item:
                        item["name"] = item["name"].replace(' ', '')  # æ ¸å¿ƒä¿®å¤
                # æŒ‰ä»£ç å»é‡
                df_temp = pd.DataFrame(data)
                df_temp = df_temp.drop_duplicates(subset=['code'], keep='first')
                data = df_temp.to_dict('records')
                
                print(f"âœ… æˆåŠŸåŠ è½½æœ¬åœ°è‡ªé€‰è‚¡ï¼Œå»é‡åå…± {len(data)} æ”¯æ ‡çš„")
                return data
            else:
                print("âš ï¸ æœ¬åœ°è‡ªé€‰è‚¡æ–‡ä»¶æ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤æ ‡çš„")
                return DEFAULT_STOCKS
        else:
            save_self_selected_stocks(DEFAULT_STOCKS)
            print("ğŸ“„ æœ¬åœ°è‡ªé€‰è‚¡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²åˆå§‹åŒ–é»˜è®¤æ ‡çš„")
            return DEFAULT_STOCKS
    except Exception as e:
        print(f"âŒ åŠ è½½è‡ªé€‰è‚¡å¤±è´¥ï¼š{e}ï¼Œä½¿ç”¨é»˜è®¤æ ‡çš„")
        return DEFAULT_STOCKS

def save_self_selected_stocks(stocks):
    """ä¿å­˜è‡ªé€‰è‚¡ï¼ˆä¿®å¤åŸç”Ÿå­—ç¬¦ä¸²replaceå‚æ•°ï¼‰"""
    try:
        # ç»Ÿä¸€è¡¥å…¨6ä½ä»£ç  + æ¸…æ´—åç§°ç©ºæ ¼ï¼ˆä¿®å¤ï¼šå»æ‰regex=Falseï¼‰
        for item in stocks:
            item["code"] = str(item["code"]).strip().zfill(6)
            if "name" in item:
                item["name"] = item["name"].replace(' ', '')  # æ ¸å¿ƒä¿®å¤
        # å»é‡åä¿å­˜
        df_temp = pd.DataFrame(stocks)
        df_temp = df_temp.drop_duplicates(subset=['code'], keep='first')
        stocks = df_temp.to_dict('records')
        
        with open(SELF_SELECTED_FILE, "w", encoding="utf-8") as f:
            json.dump(stocks, f, ensure_ascii=False, indent=2)
        print(f"âœ… è‡ªé€‰è‚¡å·²ä¿å­˜åˆ°æœ¬åœ°ï¼Œå»é‡åå…± {len(stocks)} æ”¯æ ‡çš„")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜è‡ªé€‰è‚¡å¤±è´¥ï¼š{e}")
        return False

def add_self_selected_stock(code, name):
    """æ–°å¢è‡ªé€‰è‚¡ï¼ˆä¿®å¤åŸç”Ÿå­—ç¬¦ä¸²replaceå‚æ•°ï¼‰"""
    code = str(code).strip().zfill(6)
    name = name.replace(' ', '')  # æ ¸å¿ƒä¿®å¤ï¼šå»æ‰regex=False
    stocks = load_self_selected_stocks()
    for stock in stocks:
        if stock["code"] == code:
            print(f"âš ï¸ æ ‡çš„ {code}({name}) å·²åœ¨è‡ªé€‰è‚¡ä¸­ï¼Œæ— éœ€é‡å¤æ·»åŠ ")
            return stocks
    new_stock = {"code": code, "name": name}
    stocks.append(new_stock)
    save_self_selected_stocks(stocks)
    print(f"âœ… æ–°å¢è‡ªé€‰è‚¡ï¼š{code}({name})")
    return stocks

# ====================== å…¶ä½™ä»£ç å®Œå…¨ä¸å˜ ======================
def get_xq_token():
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    }
    try:
        r = requests.get("https://xueqiu.com/", headers=headers, timeout=10)
        return r.cookies.get("xq_a_token")
    except:
        return None

def fetch_and_save_data():
    print("ğŸš€ å¯åŠ¨æ•°æ®æºåŒæ­¥ç¨‹åº...")
    
    token = get_xq_token() or xq_a_token
    headers = {
        "Cookie": f"xq_a_token={token};",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    }

    # åŠ è½½è‡ªé€‰è‚¡
    self_selected_stocks = load_self_selected_stocks()
    stock_list = pd.DataFrame(self_selected_stocks)
    # å¼ºåˆ¶è¡¥å…¨6ä½ä»£ç  + æ¸…æ´—åç§°ç©ºæ ¼ï¼ˆpandasçš„str.replaceæ”¯æŒregex=Falseï¼Œä¿ç•™ï¼‰
    stock_list['code'] = stock_list['code'].astype(str).str.zfill(6)
    stock_list['name'] = stock_list['name'].str.replace(' ', '', regex=False)
    stock_list = stock_list.to_dict('records') 
    
    csv_file = "data/dividend_data.csv"
    csv_headers = ["ä»£ç ", "åç§°", "æœ€æ–°ä»·", "æ€»å¸‚å€¼(äº¿)", "è‚¡æ¯ç‡(%)"]
    
    # åˆå§‹åŒ–CSVæ–‡ä»¶
    if not os.path.exists(csv_file):
        pd.DataFrame(columns=csv_headers).to_csv(
            csv_file, index=False, encoding='utf-8-sig'
        )
        print(f"ğŸ“„ åˆå§‹åŒ–CSVæ–‡ä»¶ï¼Œå·²å†™å…¥è¡¨å¤´ï¼š{csv_headers}")
    else:
        try:
            df_check = pd.read_csv(csv_file, nrows=1)
            if list(df_check.columns) != csv_headers:
                df_old = pd.read_csv(csv_file, header=None)
                df_old.columns = csv_headers
                df_old.to_csv(csv_file, index=False, encoding='utf-8-sig')
                print(f"ğŸ”§ ä¿®å¤CSVè¡¨å¤´ï¼Œå·²æ›´æ–°ä¸ºï¼š{csv_headers}")
        except:
            pd.DataFrame(columns=csv_headers).to_csv(
                csv_file, index=False, encoding='utf-8-sig'
            )
            print(f"ğŸ”§ CSVæ–‡ä»¶å¼‚å¸¸ï¼Œé‡æ–°åˆå§‹åŒ–å¹¶å†™å…¥è¡¨å¤´ï¼š{csv_headers}")
    
    # æ¸…ç©ºæ—§æ•°æ®
    pd.DataFrame(columns=csv_headers).to_csv(
        csv_file, index=False, encoding='utf-8-sig'
    )
    
    success_count = 0
    valid_codes = 0
    print(f"ğŸ“¥ æ­£åœ¨æŠ“å– {len(stock_list)} æ”¯è‡ªé€‰è‚¡çš„è‚¡æ¯ç‡æŒ‡æ ‡...")

    for i, stock in enumerate(stock_list):
        code = stock['code'].strip()
        # ç²¾å‡†åˆ¤æ–­é›ªçƒä»£ç å‰ç¼€
        if code.startswith(('60', '68')):
            symbol = f"SH{code}"
        elif code.startswith(('00', '30')):
            symbol = f"SZ{code}"
        elif code.startswith('8'):
            symbol = f"BJ{code}"
        else:
            print(f"âš ï¸ è·³è¿‡éAè‚¡ä»£ç ï¼š{code}")
            continue
        
        valid_codes += 1
        url = f"https://stock.xueqiu.com/v5/stock/quote.json?symbol={symbol}&extend=detail"
        
        try:
            r = requests.get(url, headers=headers, timeout=5)
            if r.status_code != 200:
                print(f"âŒ è‚¡ç¥¨ {code} å“åº”å¼‚å¸¸ï¼šçŠ¶æ€ç  {r.status_code}")
                continue
            data = r.json()
            if 'data' not in data or 'quote' not in data['data']:
                print(f"âŒ è‚¡ç¥¨ {code} æ•°æ®æ ¼å¼å¼‚å¸¸")
                continue
            
            quote_data = data['data']['quote']
            dividend_yield = quote_data.get('dividend_yield', None)
            current_price = quote_data.get('current', None)
            market_cap = quote_data.get('market_capital', None)
            
            # æ”¾å®½æ¡ä»¶ï¼šå³ä½¿è‚¡æ¯ç‡ä¸º0ä¹Ÿä¿å­˜
            if current_price is not None and market_cap is not None:
                single_data = pd.DataFrame({
                    "ä»£ç ": [code],
                    "åç§°": [stock['name']],
                    "æœ€æ–°ä»·": [current_price],
                    "æ€»å¸‚å€¼(äº¿)": [round(market_cap / 1e8, 2)],
                    "è‚¡æ¯ç‡(%)": [dividend_yield if dividend_yield is not None else 0]
                })
                single_data.to_csv(
                    csv_file, 
                    mode='a', 
                    index=False, 
                    header=False,
                    encoding='utf-8-sig'
                )
                success_count += 1
            
            time.sleep(0.2)
            
            if i % 10 == 0 and i > 0:
                print(f"âœ… å·²å¤„ç† {i} æ”¯è‚¡ç¥¨ï¼Œæœ‰æ•ˆAè‚¡ {valid_codes} æ”¯ï¼ŒæˆåŠŸæŠ“å– {success_count} æ”¯æ•°æ®...")
                
        except Exception as e:
            print(f"âŒ å¤„ç†è‚¡ç¥¨ {code} å¤±è´¥ï¼š{str(e)[:50]}")
            continue

    # æœ€ç»ˆæ’åº+å»é‡
    if os.path.exists(csv_file) and success_count > 0:
        df_final = pd.read_csv(csv_file)
        # 1. æ¸…æ´—åç§°ï¼šå»é™¤æ‰€æœ‰ç©ºæ ¼ï¼ˆpandasçš„str.replaceä¿ç•™regex=Falseï¼‰
        df_final['åç§°'] = df_final['åç§°'].str.replace(' ', '', regex=False)
        # 2. å¼ºåˆ¶è¡¥å…¨6ä½ä»£ç 
        df_final['ä»£ç '] = df_final['ä»£ç '].astype(str).str.zfill(6)
        # 3. æŒ‰ä»£ç å»é‡
        df_final = df_final.sort_values(by='è‚¡æ¯ç‡(%)', ascending=False)
        df_final = df_final.drop_duplicates(subset=['ä»£ç '], keep='first')
        # 4. é‡æ–°ä¿å­˜
        df_final.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ¨ ä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ï¼šæœ‰æ•ˆAè‚¡ {valid_codes} æ”¯ï¼Œå»é‡åå®é™…ä¿å­˜ {len(df_final)} æ”¯æ•°æ®ã€‚")
        print(f"ğŸ“ æ•°æ®å·²å­˜å…¥ {csv_file}ï¼Œå¯åœ¨Streamlitçœ‹æ¿ä¸­æŸ¥çœ‹")
    else:
        print("âš ï¸ æœªæŠ“å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥Token/ç½‘ç»œ/è‡ªé€‰è‚¡ä»£ç ")

if __name__ == "__main__":
    # add_self_selected_stock("000858", "äº”ç²®æ¶²")
    # add_self_selected_stock("600519", "è´µå·èŒ…å°")
    fetch_and_save_data()